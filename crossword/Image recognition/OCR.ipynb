{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Terminology**<br>\n",
    "*Crossword page*: The entire sheet containing the crossword puzzle and clues. <br>\n",
    "*Page pic*: A picture containing the crossword page. <br>\n",
    "*Crossgrid*: The $15\\times 15$ box on the crossword page. <br>\n",
    "*Grid pic*: The region of the sheet pic containing the crossgrid. <br>\n",
    "*Flatgrid*: The perspective-transformed grid pic. <br>\n",
    "*Smallbox*: A single cell within the crossgrid, in which the user may write a single letter. <br>\n",
    "*Black box*: A blackened smallbox. <br>\n",
    "*Clue*: The hint text associated with a word. <br>\n",
    "*Cluenum*: The number of a clue. In some cases one number may apply to 2 clues (across and down).<br>\n",
    "*Cluetype*: Direction of a word: across or down. <br>\n",
    "*ClueID*: The cluenum and cluetype identifying a clue. <br>\n",
    "*Cluebox*: A box on the crossword page containing clues. 2 clueboxes per crossword page: one for across clues and one for down clues.<br>\n",
    "*Grid coordinates*: $(y,x)$ coordinates in range $(0..14, 0..14)$ indicating the location of a smallbox within the crossgrid. $(0,0)$ is the box containing cluenum 1. <br>\n",
    "*Pixel coordinates*: $(y,x)$ coordinates indicating a pixel in an image, with $(0,0)$ at the top left of the image. <br>\n",
    "*Known letters*: A string containing known information about a word. For example, if we know it's 5 letters and the second letter is B, then the known letters are `'?B???'`. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract as pt\n",
    "pt.pytesseract.tesseract_cmd = r\"C:\\Program Files (x86)\\Tesseract-OCR\\tesseract.exe\"\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import copy\n",
    "import pandas as pd\n",
    "\n",
    "maxclues = 3 #max number of digits of a clue number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ignore for now**<br>\n",
    "`clue_dict` takes a cropped \"across\" or \"down\" image of clues (don't crop the word \"across\" or \"down\" out of the image). <br>\n",
    "Returns an assertion error if the clue numbers are unreadable. <br>\n",
    "Otherwise, returns a dictionary `cluedict` mapping clue number to clue text. <br>\n",
    "Example: `cluedict['53ACROSS'] = 'whatever the clue is for 53 across'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clue_dict(imgpath): #img is string of image path\n",
    "    \n",
    "    #read clues and split them up by line\n",
    "    text = pt.image_to_string(Image.open(imgpath))\n",
    "    text = text.split('\\n\\n')\n",
    "    \n",
    "    #determine direction of clues in img\n",
    "    if 'ACROSS' in text[0]:\n",
    "        direction = 'ACROSS'\n",
    "        del text[0]\n",
    "    elif 'DOWN' in text[0]:\n",
    "        direction = 'DOWN'\n",
    "        del text[0]\n",
    "    else: \n",
    "        direction = 'UNKNOWN'\n",
    "        \n",
    "    cluedict = {} #dictionary mapping clue number/direction to clue text\n",
    "    \n",
    "    for pos, clue in enumerate(text): #for each clue:\n",
    "        \n",
    "        #get rid of newlines within a single clue\n",
    "        clue = clue.replace('\\n', ' ')\n",
    "        \n",
    "        #figure out the clue number vs. the clue itself\n",
    "        cluestartpos = clue.find(') ')\n",
    "        numstart = cluestartpos\n",
    "        for i in reversed(range(cluestartpos)):\n",
    "            if clue[i].isnumeric():\n",
    "                numstart = i\n",
    "            else: break\n",
    "                \n",
    "        assert 0 < cluestartpos - numstart <= maxclues, 'Cannot read clue number: ' + clue\n",
    "        \n",
    "        print(cluenum, clue[cluestartpos + 2:], '\\n')\n",
    "        cluedict[cluenum] = clue[cluestartpos + 2:]\n",
    "    \n",
    "    return cluedict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ignore for now**<br>\n",
    "Contains several simple functions that might be useful later on. <br>\n",
    "`bilateral_blur(img)` smooths the image along the edges. <br>\n",
    "`canny(img)` returns binary image found by canny edge detection. <br>\n",
    "`show(img)` just plots the image using matplotlib. <br>\n",
    "`pHoff(img)` returns probabilistic line transform. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[   0,  661, 3095, 3756]],\n",
       "\n",
       "       [[1254, 1913, 3095,   72]],\n",
       "\n",
       "       [[   0, 3836,  250, 3586]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 846, 1527,  866, 1547]],\n",
       "\n",
       "       [[1273, 1938, 1300, 1965]],\n",
       "\n",
       "       [[2043, 2698, 2053, 2708]]], dtype=int32)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('pic.jpg')\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "def bilateral_blur(img):\n",
    "    blur = cv2.bilateralFilter(img,13,9,9)\n",
    "    return blur\n",
    "    #cv2.imwrite('gaussian_blur.jpg',blur,)\n",
    "    \n",
    "def canny(img): \n",
    "    return cv2.Canny(img, 255, 255)\n",
    "\n",
    "def show(img):\n",
    "    plt.imshow(img, cmap = 'gray')\n",
    "    \n",
    "def pHoff(img='pic.jpg'):\n",
    "    img = cv2.imread(img)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    #(thresh, im_bw) = cv2.threshold(gray, 128, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\n",
    "\n",
    "    #im_bw = cv2.threshold(gray, 126, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    #edges = cv2.Canny(gray,100,200,apertureSize = 3)\n",
    "    minLineLength = 100\n",
    "    maxLineGap = 10\n",
    "    lines = cv2.HoughLinesP(gray,1,np.pi/180,100,minLineLength,maxLineGap)\n",
    "    for line in lines:\n",
    "        x1,y1,x2,y2 = line[0]\n",
    "        cv2.line(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "\n",
    "    return lines\n",
    "\n",
    "pHoff()\n",
    "#cv2.imwrite('houghlines5.jpg',pHoff('pic.jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`corner_crop` takes an original image, and a 2D nparray of 4 pixel coordinates within the bounds of the image. <br><br>\n",
    "The image returned is the smallest bounding rectangle of the coordinates. If the coordinates given form a non-rectangular quadrilateral, then the regions outside this quadrilateral are blackened in the image returned. <br><br>\n",
    "For each row of the pixel coordinate array, the first entry should be the y-coordinate and the second entry should be the x-coordinate where $(0,0)$ is the top left of the image. The first row should be the upper left coordinate, second row should be upper right, third row should be lower right, and fourth row should be lower left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def corner_crop(imgpath, corners): #corners is 2D nparray. 4 rows, one for each coordinate. \n",
    "    corners = np.flip(corners, axis=1)\n",
    "    img = cv2.imread(imgpath)\n",
    "    x, y, w, h = cv2.boundingRect(corners)\n",
    "    smallimg = img[y:y+h, x:x+w].copy()\n",
    "    \n",
    "    corners -= corners.min(axis=0)\n",
    "    mask = np.zeros(smallimg.shape[:2], np.uint8)\n",
    "    cv2.drawContours(mask, [corners], -1, (255,255,255), -1, cv2.LINE_AA)\n",
    "    \n",
    "    dst = cv2.bitwise_and(smallimg, smallimg, mask=mask)\n",
    "    \n",
    "    return dst\n",
    "\n",
    "corners = np.array([[2120,240], [2115,1840], [3800,1890], [3830,150]])\n",
    "cv2.imwrite('cropp.jpg', corner_crop('pic.jpg', corners))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ignore this; its only purpose is visualization.**\n",
    "\n",
    "`markPixel` just returns an new image, identical to the image at `impath` but with a rectangular dot added. The dot is centered at the coordinates given by `pixel`, which is a tuple with order (y,x). The dot's side-length is `mark_size` pixels. The dot's grayscale color is an int in range 0..255 given by `dot_value`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def markPixel(imgpath, pixel, mark_size=30, dot_value=255):\n",
    "    y, x = pixel\n",
    "    img = cv2.imread(imgpath)\n",
    "    r = mark_size // 2 #mark radius\n",
    "    img[y-r:y+r+1, x-r:x+r+1] = 255\n",
    "    \n",
    "    return img\n",
    "\n",
    "cv2.imwrite('cropp.jpg', markPixel('pic.jpg', (3830,150)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`flatten` takes a quadrilateral region of image `impath` and returns a cropped, perspective-flattened verison of that region. <br><br>\n",
    "The quadrilaterial is specified by coordinates `corners`, which is a 2D nparray. For each row of `corners`, the first entry should be the y-coordinate and the second entry should be the x-coordinate where $(0,0)$ is the top left of the original image. The first row should be the upper left coordinate, second row should be upper right, third row should be lower right, and fourth row should be lower left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corners = np.array([[2120,240], [2115,1840], [3800,1890], [3830,150]]) #corners of crossword puzzle before transform\n",
    "\n",
    "def flatten(imgpath, corners):\n",
    "    newCorners = np.array([[0,0], [0, 999], [999, 999], [999, 0]])\n",
    "\n",
    "    corners = np.flip(corners, axis=1)\n",
    "    newCorners = np.flip(newCorners, axis=1)\n",
    "    img = cv2.imread(imgpath)\n",
    "    h, status = cv2.findHomography(corners, newCorners)\n",
    "    return cv2.warpPerspective(img, h, (1000,1000))\n",
    "\n",
    "cv2.imwrite('cropp.jpg', flatten('pic.jpg', corners))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a flatgrid at `imgpath` (as returned by the function `flatten`), and matrix coordinates `i`, `j` of the desired smallbox, `get_smallbox` returns the smallbox as an image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_smallbox(imgpath, i, j): #imgpath is the path of the transformed crossword grid\n",
    "    imgsize = 1000\n",
    "    i1, i2 = int(i * imgsize / 15), int((i+1) * imgsize / 15)\n",
    "    j1, j2 = int(j * imgsize / 15), int((j+1) * imgsize / 15)\n",
    "    smallCorners = np.array([[i1, j1], [i2, j1], [i2, j2], [i1, j2]])\n",
    "    smallImg = corner_crop(imgpath, smallCorners)\n",
    "    return cv2.cvtColor(smallImg, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cv2.imwrite('small.jpg', get_smallbox('cropp.jpg', 1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a flatgrid at `imgpath`, `black_coords` returns a 2D nparray whose rows are the grid coordinates of all black boxes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def black_coords(imgpath): #imgpath is the path of the transformed crossword grid\n",
    "    data = np.zeros((15, 15))\n",
    "    for i in range(15):\n",
    "        for j in range(15):\n",
    "            data[i, j] = getSquare('cropp.jpg', i, j).mean()\n",
    "\n",
    "    sortedData = np.msort(data.flatten()) #sorted mean values\n",
    "    shifted = np.append(sortedData, sortedData[-1]) #shifted has something at end of array\n",
    "    diffs = shifted - np.insert(sortedData, 0, sortedData[0])\n",
    "    numblack = np.argmax(diffs) #tells us how many black boxes there are\n",
    "    threshold = np.mean(sortedData[numblack - 1:numblack+1])\n",
    "    blackboxes = np.where(data < threshold)\n",
    "    return np.concatenate((blackboxes[0].reshape(-1,1), blackboxes[1].reshape(-1,1)), axis=1)\n",
    "\n",
    "blacks = black_coords('cropp.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a 2D nparray as returned by `black_coords`, `blacks_to_grid` returns the crossgrid layout, and the word list. <br><br>\n",
    "The crossgrid layout is a $15\\times 15$ nparray, each value representing the smallbox with corresponding grid coordinates. Value 255 indicates a black box, value 0 indicates a white box containing no cluenum, and other values are positive integers indicating the cluenum associated with that smallbox. <br><br>\n",
    "The word list is a dictionary whose keys are clueIDs (e.g., `'5 Down'`), and values are the known letters of the word at that clueID (e.g., `'cro??word'`). Word list contains one entry for each clueID. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blacks_to_grid(blacks):\n",
    "    printgrid = np.zeros((15, 15))\n",
    "    printgrid[blacks[:,0],blacks[:,1]] = 255\n",
    "    refgrid = copy.deepcopy(printgrid)\n",
    "    counter, cluelist = 1, {}\n",
    "    for i in range(15):\n",
    "        for j in range(15):\n",
    "            down, across = False, False\n",
    "            if i==0 and refgrid[i,j]==0:\n",
    "                down = True\n",
    "            if j==0 and refgrid[i,j]==0:\n",
    "                across = True\n",
    "            if j > 0 and refgrid[i,j-1] == 255 and refgrid[i,j] == 0:\n",
    "                across = True\n",
    "            if i > 0 and refgrid[i-1,j] == 255 and refgrid[i,j] == 0:\n",
    "                down = True\n",
    "            if down:\n",
    "                below = refgrid[i:15,j]\n",
    "                if len(np.where(below==255)[0]) == 0:\n",
    "                    word_len = 15 - i\n",
    "                else: word_len = np.where(below==255)[0][0]\n",
    "                cluelist[str(counter)+' Down'] = '?' * word_len\n",
    "            if across: \n",
    "                below = refgrid[i,j:15]\n",
    "                if len(np.where(below==255)[0]) == 0:\n",
    "                    word_len = 15 - j\n",
    "                else: word_len = np.where(below==255)[0][0]\n",
    "                cluelist[str(counter)+' Across'] = '?' * word_len\n",
    "            if down or across:\n",
    "                printgrid[i,j] = counter\n",
    "                counter += 1\n",
    "    return printgrid, cluelist\n",
    "        \n",
    "printgrid, cluelist = blacks_to_grid(blacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x242d3e05be0>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(printgrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1 Down': '????',\n",
       " '1 Across': '?????',\n",
       " '2 Down': '????',\n",
       " '3 Down': '????',\n",
       " '4 Down': '??????',\n",
       " '5 Down': '???????',\n",
       " '6 Down': '????',\n",
       " '6 Across': '????',\n",
       " '7 Down': '???????????????',\n",
       " '8 Down': '?????',\n",
       " '9 Down': '??????',\n",
       " '10 Down': '????????',\n",
       " '10 Across': '????',\n",
       " '11 Down': '????',\n",
       " '12 Down': '????',\n",
       " '13 Down': '????',\n",
       " '14 Across': '?????',\n",
       " '15 Across': '????',\n",
       " '16 Across': '????',\n",
       " '17 Across': '?????',\n",
       " '18 Across': '????',\n",
       " '19 Across': '????',\n",
       " '20 Across': '?????',\n",
       " '21 Across': '????',\n",
       " '22 Across': '????',\n",
       " '23 Across': '???',\n",
       " '24 Down': '????',\n",
       " '25 Across': '?????',\n",
       " '26 Down': '???',\n",
       " '27 Down': '?????',\n",
       " '27 Across': '????????',\n",
       " '28 Down': '?????',\n",
       " '29 Down': '?????',\n",
       " '30 Down': '????',\n",
       " '31 Across': '??????',\n",
       " '32 Down': '?????',\n",
       " '33 Down': '?????',\n",
       " '34 Down': '?????',\n",
       " '35 Across': '???',\n",
       " '36 Across': '?????',\n",
       " '37 Down': '????',\n",
       " '38 Across': '?????',\n",
       " '39 Across': '????',\n",
       " '40 Down': '????????',\n",
       " '41 Across': '?????',\n",
       " '42 Down': '????',\n",
       " '43 Across': '????',\n",
       " '44 Across': '?????',\n",
       " '45 Down': '???',\n",
       " '46 Across': '?????',\n",
       " '47 Down': '???????',\n",
       " '48 Across': '???',\n",
       " '49 Across': '??????',\n",
       " '50 Down': '??????',\n",
       " '51 Across': '????????',\n",
       " '52 Down': '??????',\n",
       " '53 Across': '?????',\n",
       " '54 Down': '?????',\n",
       " '55 Across': '???',\n",
       " '56 Down': '????',\n",
       " '56 Across': '????',\n",
       " '57 Down': '????',\n",
       " '58 Down': '????',\n",
       " '59 Across': '????',\n",
       " '60 Down': '????',\n",
       " '61 Across': '?????',\n",
       " '62 Down': '????',\n",
       " '63 Down': '????',\n",
       " '64 Down': '????',\n",
       " '65 Across': '????',\n",
       " '66 Across': '????',\n",
       " '67 Across': '?????',\n",
       " '68 Across': '????',\n",
       " '69 Across': '????',\n",
       " '70 Across': '?????',\n",
       " '71 Across': '????',\n",
       " '72 Across': '????',\n",
       " '73 Across': '?????'}"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NEXT STEPS**<br>\n",
    "Compile the above functions into a class where the constructor takes in a page pic and creates a crossword object. Current capabilities:\n",
    "* Access the crossgrid representation.\n",
    "* Access the flattened image of any smallbox by giving coordinates.\n",
    "* Access the list of clueIDs and known letters. \n",
    "\n",
    "**CAPABILITIES TO ADD:**\n",
    "1. Given a page pic, locate the clue boxes, and OCR-read the clueIDs and clues. \n",
    "    * Given a clueID, return the clue text. \n",
    "    * Need to report errors to user if clue numbers are not distinguishable/readable. \n",
    "2. Given a clue's text and the known letters, get the solutions and confidences from dictionary.com tool. \n",
    "    * Need to account for cases when the tool says \"No answers for that clue\". \n",
    "3. Given a flattened smallbox, determine whether a letter has been written. \n",
    "    * If yes, then use the pretrained neural net to recognize the letter. \n",
    "    * This requires first getting rid of the cluenum (if applicable) before feeding image into neural net. \n",
    "    * We also may want to pad the image with a background value to fit the neural net's image size.\n",
    "    \n",
    "4. Have a way to edit the crossword object when a letter is read or a clue is solved. \n",
    "    * This should automatically update all known letter strings, and check for conflicts with existing information. \n",
    "5. Given multiple solutions and confidences for multiple clues, need a probabilistic way to resolve conflicts. \n",
    "    * Will be difficult. \n",
    "6. Need a graphical interface to incrementally report results to user (partially to understand where errors might have occurred). \n",
    "    1. Flattened pics of crossgrid and cluebox. \n",
    "    2. Digital representation of empty crossgrid. \n",
    "    3. OCR readings of clues. \n",
    "    4. Results of handwriting recognition. \n",
    "    5. Word guesses + confidences for each clue. \n",
    "    6. Letter guesses + confidences for each smallbox. \n",
    "    7. Final proposed solution (with some blank spaces if we couldn't complete the solution). "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
